{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import json\n",
    "import glob\n",
    "from docx import Document\n",
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt_parts(document_part: str):\n",
    "    \"\"\"\n",
    "    Build the prompt parts as input to the model\n",
    "\n",
    "    Args:\n",
    "        document_part (str): String that has the resume data\n",
    "    \"\"\"\n",
    "    prompt_parts = [\n",
    "        \"Extract the following details from this resume in JSON format:\",\n",
    "        \"Name, Email, Skills\",\n",
    "        document_part\n",
    "    ]\n",
    "    return prompt_parts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resume_details_from_pdf(pdf_file_path: str, model: GenerativeModel):\n",
    "    \"\"\"\n",
    "    Processes a PDF document resume using Gemini 2.5 Flash and extracts details.\n",
    "\n",
    "    Args:\n",
    "        pdf_file_path (str): path to pdf file to be processed\n",
    "        model (GenerativeModel): Generative model to be used\n",
    "    \"\"\"\n",
    "    with open(pdf_file_path, \"rb\") as f:\n",
    "        pdf_content = f.read()\n",
    "    pdf_part = Part.from_data(data=pdf_content, mime_type=\"application/pdf\")\n",
    "    prompt_parts = build_prompt_parts(pdf_part)\n",
    "    response = model.generate_content(prompt_parts)\n",
    "    return response.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resume_details_from_doc(docx_file_path: str, model: GenerativeModel):\n",
    "    \"\"\"\n",
    "    Processes a Word document resume using Gemini 2.5 Flash and extracts details.\n",
    "\n",
    "    Args:\n",
    "        docx_file_path (str): path to docx file to be processed\n",
    "        model (GenerativeModel): Generative model to be used\n",
    "    \"\"\"\n",
    "    document = Document(docx_file_path)\n",
    "    text = ''\n",
    "    for paragraph in document.paragraphs:\n",
    "        text += f'{paragraph.text}\\n'\n",
    "    prompt_parts = build_prompt_parts(text)\n",
    "    response = model.generate_content(prompt_parts)\n",
    "    return response.text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_string_to_json(response: str):\n",
    "    \"\"\"\n",
    "    Parse the resulting string into a JSON object\n",
    "\n",
    "    Args:\n",
    "        response (str): text response from generate_content function by the generative AI model\n",
    "    \"\"\"\n",
    "    dict_output = json.loads(response.replace('`', '').replace('\\n', '')[4:])\n",
    "    skills = [skill for skill in dict_output['Skills']]\n",
    "    json_output = {\n",
    "        'Name': dict_output['Name'],\n",
    "        'Email': dict_output['Email'],\n",
    "        'Skills': skills\n",
    "    }\n",
    "    return json_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_json(json_file_name: str, json_output: dict):\n",
    "    \"\"\"\n",
    "    Write the resulting JSON object into a JSON file\n",
    "\n",
    "    Args:\n",
    "        json_file_name (str): file name to be assigned to the JSON file being saved.\n",
    "        json_output (dict): content of the JSON file being saved\n",
    "    \"\"\"\n",
    "    with open(json_file_name, \"w\") as f:\n",
    "        json.dump(json_output, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(docx_paths: List[str], pdf_paths: List[str], model: GenerativeModel):\n",
    "    \"\"\"\n",
    "    Main processing function to generate parsed pdf and docx resumes and write the results to json files\n",
    "\n",
    "    Args:\n",
    "        docx_paths (List[str]): list of paths to docx files.\n",
    "        pdf_paths (List[str]): list of paths to pdf files.\n",
    "        model (GenerativeModel): Generative model to be used\n",
    "    \"\"\"\n",
    "    for docx_path in docx_paths:\n",
    "        response = get_resume_details_from_doc(docx_path, model)\n",
    "        json_output = parse_string_to_json(response)\n",
    "        json_file_name = docx_path.replace('/data/', '/reports/').replace('.docx', '.json')\n",
    "        write_json(json_file_name, json_output)\n",
    "    for pdf_path in pdf_paths:\n",
    "        response = get_resume_details_from_pdf(pdf_path, model)\n",
    "        json_output = parse_string_to_json(response)\n",
    "        json_file_name = pdf_path.replace('/data/', '/reports/').replace('.pdf', '.json')\n",
    "        write_json(json_file_name, json_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the main function\n",
    "if __name__ == \"__main__\":\n",
    "    vertexai.init()\n",
    "    model = GenerativeModel(\"gemini-2.5-flash\")\n",
    "    docx_paths = [path for path in glob.glob('../data/*') if '.docx' in path]\n",
    "    pdf_paths = [path for path in glob.glob('../data/*') if '.pdf' in path]\n",
    "    main(docx_paths, pdf_paths, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
